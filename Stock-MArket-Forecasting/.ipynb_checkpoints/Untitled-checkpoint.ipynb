{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Market Prediction And Forecasting Using Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keras and Tensorflow >2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Collection\n",
    "import pandas_datareader as pdr\n",
    "key=\"c76497b55eb2989387c93d0efb328c2af34db0b2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.get_data_tiingo('AAPL', api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>divCash</th>\n",
       "      <th>splitFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-01-04 00:00:00+00:00</td>\n",
       "      <td>105.35</td>\n",
       "      <td>105.368</td>\n",
       "      <td>102.00</td>\n",
       "      <td>102.61</td>\n",
       "      <td>67649387</td>\n",
       "      <td>24.397857</td>\n",
       "      <td>24.402026</td>\n",
       "      <td>23.622035</td>\n",
       "      <td>23.763304</td>\n",
       "      <td>270597548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-01-05 00:00:00+00:00</td>\n",
       "      <td>102.71</td>\n",
       "      <td>105.850</td>\n",
       "      <td>102.41</td>\n",
       "      <td>105.75</td>\n",
       "      <td>55790992</td>\n",
       "      <td>23.786463</td>\n",
       "      <td>24.513651</td>\n",
       "      <td>23.716987</td>\n",
       "      <td>24.490493</td>\n",
       "      <td>223163968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-01-06 00:00:00+00:00</td>\n",
       "      <td>100.70</td>\n",
       "      <td>102.370</td>\n",
       "      <td>99.87</td>\n",
       "      <td>100.56</td>\n",
       "      <td>68457388</td>\n",
       "      <td>23.320970</td>\n",
       "      <td>23.707723</td>\n",
       "      <td>23.128752</td>\n",
       "      <td>23.288548</td>\n",
       "      <td>273829552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-01-07 00:00:00+00:00</td>\n",
       "      <td>96.45</td>\n",
       "      <td>100.130</td>\n",
       "      <td>96.43</td>\n",
       "      <td>98.68</td>\n",
       "      <td>81094428</td>\n",
       "      <td>22.336719</td>\n",
       "      <td>23.188965</td>\n",
       "      <td>22.332087</td>\n",
       "      <td>22.853161</td>\n",
       "      <td>324377712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2016-01-08 00:00:00+00:00</td>\n",
       "      <td>96.96</td>\n",
       "      <td>99.110</td>\n",
       "      <td>96.76</td>\n",
       "      <td>98.55</td>\n",
       "      <td>70798016</td>\n",
       "      <td>22.454829</td>\n",
       "      <td>22.952744</td>\n",
       "      <td>22.408511</td>\n",
       "      <td>22.823055</td>\n",
       "      <td>283192064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                       date   close     high     low    open  \\\n",
       "0   AAPL  2016-01-04 00:00:00+00:00  105.35  105.368  102.00  102.61   \n",
       "1   AAPL  2016-01-05 00:00:00+00:00  102.71  105.850  102.41  105.75   \n",
       "2   AAPL  2016-01-06 00:00:00+00:00  100.70  102.370   99.87  100.56   \n",
       "3   AAPL  2016-01-07 00:00:00+00:00   96.45  100.130   96.43   98.68   \n",
       "4   AAPL  2016-01-08 00:00:00+00:00   96.96   99.110   96.76   98.55   \n",
       "\n",
       "     volume   adjClose    adjHigh     adjLow    adjOpen  adjVolume  divCash  \\\n",
       "0  67649387  24.397857  24.402026  23.622035  23.763304  270597548      0.0   \n",
       "1  55790992  23.786463  24.513651  23.716987  24.490493  223163968      0.0   \n",
       "2  68457388  23.320970  23.707723  23.128752  23.288548  273829552      0.0   \n",
       "3  81094428  22.336719  23.188965  22.332087  22.853161  324377712      0.0   \n",
       "4  70798016  22.454829  22.952744  22.408511  22.823055  283192064      0.0   \n",
       "\n",
       "   splitFactor  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>divCash</th>\n",
       "      <th>splitFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-22 00:00:00+00:00</td>\n",
       "      <td>131.88</td>\n",
       "      <td>134.405</td>\n",
       "      <td>129.6500</td>\n",
       "      <td>131.61</td>\n",
       "      <td>169351825</td>\n",
       "      <td>131.88</td>\n",
       "      <td>134.405</td>\n",
       "      <td>129.6500</td>\n",
       "      <td>131.61</td>\n",
       "      <td>169351825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-23 00:00:00+00:00</td>\n",
       "      <td>130.96</td>\n",
       "      <td>132.430</td>\n",
       "      <td>130.7800</td>\n",
       "      <td>132.16</td>\n",
       "      <td>88223692</td>\n",
       "      <td>130.96</td>\n",
       "      <td>132.430</td>\n",
       "      <td>130.7800</td>\n",
       "      <td>132.16</td>\n",
       "      <td>88223692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-24 00:00:00+00:00</td>\n",
       "      <td>131.97</td>\n",
       "      <td>133.460</td>\n",
       "      <td>131.1000</td>\n",
       "      <td>131.32</td>\n",
       "      <td>54930064</td>\n",
       "      <td>131.97</td>\n",
       "      <td>133.460</td>\n",
       "      <td>131.1000</td>\n",
       "      <td>131.32</td>\n",
       "      <td>54930064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-28 00:00:00+00:00</td>\n",
       "      <td>136.69</td>\n",
       "      <td>137.340</td>\n",
       "      <td>133.5100</td>\n",
       "      <td>133.99</td>\n",
       "      <td>123124632</td>\n",
       "      <td>136.69</td>\n",
       "      <td>137.340</td>\n",
       "      <td>133.5100</td>\n",
       "      <td>133.99</td>\n",
       "      <td>123124632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-12-29 00:00:00+00:00</td>\n",
       "      <td>134.87</td>\n",
       "      <td>138.789</td>\n",
       "      <td>134.3409</td>\n",
       "      <td>138.05</td>\n",
       "      <td>121047324</td>\n",
       "      <td>134.87</td>\n",
       "      <td>138.789</td>\n",
       "      <td>134.3409</td>\n",
       "      <td>138.05</td>\n",
       "      <td>121047324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                       date   close     high       low    open  \\\n",
       "1252   AAPL  2020-12-22 00:00:00+00:00  131.88  134.405  129.6500  131.61   \n",
       "1253   AAPL  2020-12-23 00:00:00+00:00  130.96  132.430  130.7800  132.16   \n",
       "1254   AAPL  2020-12-24 00:00:00+00:00  131.97  133.460  131.1000  131.32   \n",
       "1255   AAPL  2020-12-28 00:00:00+00:00  136.69  137.340  133.5100  133.99   \n",
       "1256   AAPL  2020-12-29 00:00:00+00:00  134.87  138.789  134.3409  138.05   \n",
       "\n",
       "         volume  adjClose  adjHigh    adjLow  adjOpen  adjVolume  divCash  \\\n",
       "1252  169351825    131.88  134.405  129.6500   131.61  169351825      0.0   \n",
       "1253   88223692    130.96  132.430  130.7800   132.16   88223692      0.0   \n",
       "1254   54930064    131.97  133.460  131.1000   131.32   54930064      0.0   \n",
       "1255  123124632    136.69  137.340  133.5100   133.99  123124632      0.0   \n",
       "1256  121047324    134.87  138.789  134.3409   138.05  121047324      0.0   \n",
       "\n",
       "      splitFactor  \n",
       "1252          1.0  \n",
       "1253          1.0  \n",
       "1254          1.0  \n",
       "1255          1.0  \n",
       "1256          1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.reset_index()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       105.35\n",
       "1       102.71\n",
       "2       100.70\n",
       "3        96.45\n",
       "4        96.96\n",
       "         ...  \n",
       "1252    131.88\n",
       "1253    130.96\n",
       "1254    131.97\n",
       "1255    136.69\n",
       "1256    134.87\n",
       "Name: close, Length: 1257, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x254f4255070>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM are sensitive to the scale of the data. so we apply MinMax scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       105.35\n",
       "1       102.71\n",
       "2       100.70\n",
       "3        96.45\n",
       "4        96.96\n",
       "         ...  \n",
       "1252    131.88\n",
       "1253    130.96\n",
       "1254    131.97\n",
       "1255    136.69\n",
       "1256    134.87\n",
       "Name: close, Length: 1257, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03610343]\n",
      " [0.02975346]\n",
      " [0.02491882]\n",
      " ...\n",
      " [0.10013229]\n",
      " [0.11148527]\n",
      " [0.10710764]]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting dataset into train and test split\n",
    "training_size=int(len(df1)*0.65)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 440)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03610343],\n",
       "       [0.02975346],\n",
       "       [0.02491882],\n",
       "       [0.01469633],\n",
       "       [0.01592303],\n",
       "       [0.01969934],\n",
       "       [0.02313891],\n",
       "       [0.01695731],\n",
       "       [0.02208058],\n",
       "       [0.01633193],\n",
       "       [0.01520144],\n",
       "       [0.01551413],\n",
       "       [0.01433554],\n",
       "       [0.02665063],\n",
       "       [0.02188815],\n",
       "       [0.02321106],\n",
       "       [0.0074083 ],\n",
       "       [0.00901984],\n",
       "       [0.01683704],\n",
       "       [0.01464823],\n",
       "       [0.00995791],\n",
       "       [0.0144558 ],\n",
       "       [0.01505713],\n",
       "       [0.00885147],\n",
       "       [0.01123271],\n",
       "       [0.01118461],\n",
       "       [0.0094528 ],\n",
       "       [0.00808178],\n",
       "       [0.00877931],\n",
       "       [0.01515334],\n",
       "       [0.01871317],\n",
       "       [0.01423933],\n",
       "       [0.01371016],\n",
       "       [0.01573061],\n",
       "       [0.01046302],\n",
       "       [0.01385448],\n",
       "       [0.01544197],\n",
       "       [0.01580277],\n",
       "       [0.0152736 ],\n",
       "       [0.02450992],\n",
       "       [0.02503909],\n",
       "       [0.02684305],\n",
       "       [0.03047505],\n",
       "       [0.02773301],\n",
       "       [0.02571257],\n",
       "       [0.02592904],\n",
       "       [0.02604931],\n",
       "       [0.02867108],\n",
       "       [0.02929645],\n",
       "       [0.03425135],\n",
       "       [0.03759471],\n",
       "       [0.03718581],\n",
       "       [0.03747444],\n",
       "       [0.03745039],\n",
       "       [0.03939868],\n",
       "       [0.03797956],\n",
       "       [0.03687312],\n",
       "       [0.03571858],\n",
       "       [0.04170776],\n",
       "       [0.04622971],\n",
       "       [0.04485869],\n",
       "       [0.04726398],\n",
       "       [0.04998196],\n",
       "       [0.04683103],\n",
       "       [0.04959711],\n",
       "       [0.04377631],\n",
       "       [0.04406494],\n",
       "       [0.04493085],\n",
       "       [0.04834636],\n",
       "       [0.05219483],\n",
       "       [0.05233915],\n",
       "       [0.04692724],\n",
       "       [0.0412267 ],\n",
       "       [0.03985568],\n",
       "       [0.04038485],\n",
       "       [0.03759471],\n",
       "       [0.03689717],\n",
       "       [0.035454  ],\n",
       "       [0.03369814],\n",
       "       [0.01799158],\n",
       "       [0.01079976],\n",
       "       [0.00817799],\n",
       "       [0.00793746],\n",
       "       [0.01164161],\n",
       "       [0.00926037],\n",
       "       [0.00697535],\n",
       "       [0.00572459],\n",
       "       [0.00589296],\n",
       "       [0.0074083 ],\n",
       "       [0.00521948],\n",
       "       [0.        ],\n",
       "       [0.00043295],\n",
       "       [0.00851473],\n",
       "       [0.00757667],\n",
       "       [0.01015033],\n",
       "       [0.00928443],\n",
       "       [0.01173782],\n",
       "       [0.01464823],\n",
       "       [0.018184  ],\n",
       "       [0.02232111],\n",
       "       [0.02422129],\n",
       "       [0.02407697],\n",
       "       [0.02289838],\n",
       "       [0.01953097],\n",
       "       [0.01775105],\n",
       "       [0.01823211],\n",
       "       [0.01993987],\n",
       "       [0.02090198],\n",
       "       [0.02068551],\n",
       "       [0.02239327],\n",
       "       [0.02042093],\n",
       "       [0.01683704],\n",
       "       [0.01712568],\n",
       "       [0.01635598],\n",
       "       [0.01734215],\n",
       "       [0.01200241],\n",
       "       [0.01144919],\n",
       "       [0.01339747],\n",
       "       [0.01253157],\n",
       "       [0.01385448],\n",
       "       [0.00736019],\n",
       "       [0.004089  ],\n",
       "       [0.0078172 ],\n",
       "       [0.00976548],\n",
       "       [0.01265183],\n",
       "       [0.01334937],\n",
       "       [0.01118461],\n",
       "       [0.01248346],\n",
       "       [0.01346963],\n",
       "       [0.01524955],\n",
       "       [0.01597114],\n",
       "       [0.01702946],\n",
       "       [0.01570655],\n",
       "       [0.02032471],\n",
       "       [0.02030066],\n",
       "       [0.02282622],\n",
       "       [0.02292243],\n",
       "       [0.02313891],\n",
       "       [0.0218641 ],\n",
       "       [0.02001203],\n",
       "       [0.01683704],\n",
       "       [0.0152255 ],\n",
       "       [0.03033073],\n",
       "       [0.03367408],\n",
       "       [0.0333614 ],\n",
       "       [0.03778713],\n",
       "       [0.03401082],\n",
       "       [0.03716176],\n",
       "       [0.03735418],\n",
       "       [0.0412267 ],\n",
       "       [0.04336741],\n",
       "       [0.04442574],\n",
       "       [0.04247745],\n",
       "       [0.04230908],\n",
       "       [0.0429104 ],\n",
       "       [0.04603728],\n",
       "       [0.04579675],\n",
       "       [0.04541191],\n",
       "       [0.04507517],\n",
       "       [0.04574865],\n",
       "       [0.04370415],\n",
       "       [0.04452195],\n",
       "       [0.04254961],\n",
       "       [0.04144317],\n",
       "       [0.03992784],\n",
       "       [0.03963921],\n",
       "       [0.03766687],\n",
       "       [0.0379074 ],\n",
       "       [0.03942273],\n",
       "       [0.04182802],\n",
       "       [0.04175586],\n",
       "       [0.04334336],\n",
       "       [0.03651233],\n",
       "       [0.03076368],\n",
       "       [0.0363199 ],\n",
       "       [0.04235719],\n",
       "       [0.0515454 ],\n",
       "       [0.06068551],\n",
       "       [0.05912207],\n",
       "       [0.05589898],\n",
       "       [0.05587492],\n",
       "       [0.05582682],\n",
       "       [0.05840048],\n",
       "       [0.05380637],\n",
       "       [0.05421527],\n",
       "       [0.05472038],\n",
       "       [0.05678894],\n",
       "       [0.05253157],\n",
       "       [0.05462417],\n",
       "       [0.05334937],\n",
       "       [0.05450391],\n",
       "       [0.05462417],\n",
       "       [0.05664462],\n",
       "       [0.05705352],\n",
       "       [0.06184005],\n",
       "       [0.06244137],\n",
       "       [0.06494287],\n",
       "       [0.06407697],\n",
       "       [0.06564041],\n",
       "       [0.06544799],\n",
       "       [0.06525556],\n",
       "       [0.06441371],\n",
       "       [0.06426939],\n",
       "       [0.06316296],\n",
       "       [0.06568851],\n",
       "       [0.06713169],\n",
       "       [0.06073361],\n",
       "       [0.05806374],\n",
       "       [0.05623572],\n",
       "       [0.05580277],\n",
       "       [0.05087192],\n",
       "       [0.05111245],\n",
       "       [0.04687913],\n",
       "       [0.0444979 ],\n",
       "       [0.0482742 ],\n",
       "       [0.04983764],\n",
       "       [0.04940469],\n",
       "       [0.04197234],\n",
       "       [0.04351173],\n",
       "       [0.03696933],\n",
       "       [0.04033674],\n",
       "       [0.04726398],\n",
       "       [0.04716777],\n",
       "       [0.04743235],\n",
       "       [0.05144919],\n",
       "       [0.05161756],\n",
       "       [0.05024654],\n",
       "       [0.05159351],\n",
       "       [0.05106434],\n",
       "       [0.05079976],\n",
       "       [0.04853879],\n",
       "       [0.04606133],\n",
       "       [0.0470475 ],\n",
       "       [0.04514732],\n",
       "       [0.04716777],\n",
       "       [0.04976548],\n",
       "       [0.05238725],\n",
       "       [0.05678894],\n",
       "       [0.0552255 ],\n",
       "       [0.0597715 ],\n",
       "       [0.0597715 ],\n",
       "       [0.06128683],\n",
       "       [0.06164762],\n",
       "       [0.06325917],\n",
       "       [0.06400481],\n",
       "       [0.06426939],\n",
       "       [0.06241732],\n",
       "       [0.06297054],\n",
       "       [0.06475045],\n",
       "       [0.06354781],\n",
       "       [0.06347565],\n",
       "       [0.06128683],\n",
       "       [0.06208058],\n",
       "       [0.06176789],\n",
       "       [0.06318701],\n",
       "       [0.06631389],\n",
       "       [0.06891161],\n",
       "       [0.06920024],\n",
       "       [0.07073963],\n",
       "       [0.06953698],\n",
       "       [0.06903187],\n",
       "       [0.07134095],\n",
       "       [0.0713169 ],\n",
       "       [0.07081179],\n",
       "       [0.07134095],\n",
       "       [0.07153337],\n",
       "       [0.07126879],\n",
       "       [0.0758629 ],\n",
       "       [0.07600722],\n",
       "       [0.07603127],\n",
       "       [0.07526158],\n",
       "       [0.07458809],\n",
       "       [0.09238725],\n",
       "       [0.09185809],\n",
       "       [0.093181  ],\n",
       "       [0.0960914 ],\n",
       "       [0.09907396],\n",
       "       [0.10030066],\n",
       "       [0.10121467],\n",
       "       [0.10049308],\n",
       "       [0.10330728],\n",
       "       [0.10746843],\n",
       "       [0.10864702],\n",
       "       [0.10825015],\n",
       "       [0.10915213],\n",
       "       [0.11150932],\n",
       "       [0.11249549],\n",
       "       [0.11110042],\n",
       "       [0.11141311],\n",
       "       [0.11206254],\n",
       "       [0.11220686],\n",
       "       [0.11894167],\n",
       "       [0.11694528],\n",
       "       [0.11891762],\n",
       "       [0.11785929],\n",
       "       [0.11829224],\n",
       "       [0.11704149],\n",
       "       [0.1162718 ],\n",
       "       [0.11737823],\n",
       "       [0.11752255],\n",
       "       [0.11701744],\n",
       "       [0.12055322],\n",
       "       [0.12110643],\n",
       "       [0.11942273],\n",
       "       [0.12295851],\n",
       "       [0.11906194],\n",
       "       [0.1228623 ],\n",
       "       [0.12165965],\n",
       "       [0.12098617],\n",
       "       [0.12156344],\n",
       "       [0.12858689],\n",
       "       [0.12935658],\n",
       "       [0.12889958],\n",
       "       [0.12825015],\n",
       "       [0.12834636],\n",
       "       [0.13092002],\n",
       "       [0.12911606],\n",
       "       [0.12825015],\n",
       "       [0.12748046],\n",
       "       [0.12707156],\n",
       "       [0.12336741],\n",
       "       [0.12377631],\n",
       "       [0.12197234],\n",
       "       [0.12384847],\n",
       "       [0.12233313],\n",
       "       [0.12108238],\n",
       "       [0.12531569],\n",
       "       [0.12490679],\n",
       "       [0.12820204],\n",
       "       [0.13034275],\n",
       "       [0.12829826],\n",
       "       [0.12856284],\n",
       "       [0.1282261 ],\n",
       "       [0.1352736 ],\n",
       "       [0.13751052],\n",
       "       [0.13642814],\n",
       "       [0.13515334],\n",
       "       [0.1409982 ],\n",
       "       [0.15073963],\n",
       "       [0.15309681],\n",
       "       [0.15134095],\n",
       "       [0.1530006 ],\n",
       "       [0.15817198],\n",
       "       [0.15720986],\n",
       "       [0.15665664],\n",
       "       [0.14410102],\n",
       "       [0.14960914],\n",
       "       [0.15085989],\n",
       "       [0.15309681],\n",
       "       [0.15263981],\n",
       "       [0.15153337],\n",
       "       [0.15280818],\n",
       "       [0.1521828 ],\n",
       "       [0.15232712],\n",
       "       [0.1501383 ],\n",
       "       [0.15114853],\n",
       "       [0.15660854],\n",
       "       [0.1529525 ],\n",
       "       [0.15420325],\n",
       "       [0.15641612],\n",
       "       [0.1555021 ],\n",
       "       [0.1410463 ],\n",
       "       [0.13248346],\n",
       "       [0.13529765],\n",
       "       [0.13185809],\n",
       "       [0.12976548],\n",
       "       [0.12490679],\n",
       "       [0.13469633],\n",
       "       [0.13149729],\n",
       "       [0.13356584],\n",
       "       [0.13298857],\n",
       "       [0.13455201],\n",
       "       [0.13344558],\n",
       "       [0.12841852],\n",
       "       [0.13346963],\n",
       "       [0.12829826],\n",
       "       [0.12911606],\n",
       "       [0.1278653 ],\n",
       "       [0.12928443],\n",
       "       [0.12601323],\n",
       "       [0.1295009 ],\n",
       "       [0.13161756],\n",
       "       [0.13274805],\n",
       "       [0.13325316],\n",
       "       [0.1381359 ],\n",
       "       [0.14119062],\n",
       "       [0.14244137],\n",
       "       [0.14369212],\n",
       "       [0.1459531 ],\n",
       "       [0.1443175 ],\n",
       "       [0.14414913],\n",
       "       [0.14852676],\n",
       "       [0.1500902 ],\n",
       "       [0.15182201],\n",
       "       [0.14484666],\n",
       "       [0.14229705],\n",
       "       [0.14044498],\n",
       "       [0.14361996],\n",
       "       [0.16067348],\n",
       "       [0.15689717],\n",
       "       [0.15886951],\n",
       "       [0.16469032],\n",
       "       [0.16774504],\n",
       "       [0.17010222],\n",
       "       [0.15629585],\n",
       "       [0.16149128],\n",
       "       [0.16719182],\n",
       "       [0.17140108],\n",
       "       [0.16983764],\n",
       "       [0.16240529],\n",
       "       [0.16153939],\n",
       "       [0.16084185],\n",
       "       [0.16702345],\n",
       "       [0.16750451],\n",
       "       [0.16579675],\n",
       "       [0.16721587],\n",
       "       [0.17108839],\n",
       "       [0.17455201],\n",
       "       [0.17561034],\n",
       "       [0.17717378],\n",
       "       [0.17729405],\n",
       "       [0.17255562],\n",
       "       [0.17214672],\n",
       "       [0.17058328],\n",
       "       [0.16425737],\n",
       "       [0.17116055],\n",
       "       [0.16962117],\n",
       "       [0.16671076],\n",
       "       [0.16341551],\n",
       "       [0.16726398],\n",
       "       [0.16435358],\n",
       "       [0.1644979 ],\n",
       "       [0.15809982],\n",
       "       [0.15165364],\n",
       "       [0.1480457 ],\n",
       "       [0.14482261],\n",
       "       [0.15105232],\n",
       "       [0.15367408],\n",
       "       [0.15138906],\n",
       "       [0.1534095 ],\n",
       "       [0.15266386],\n",
       "       [0.15427541],\n",
       "       [0.15187011],\n",
       "       [0.15646422],\n",
       "       [0.15624775],\n",
       "       [0.1575466 ],\n",
       "       [0.15769092],\n",
       "       [0.15925436],\n",
       "       [0.15793145],\n",
       "       [0.16031269],\n",
       "       [0.16726398],\n",
       "       [0.1686831 ],\n",
       "       [0.16697535],\n",
       "       [0.15788334],\n",
       "       [0.15853277],\n",
       "       [0.15834035],\n",
       "       [0.16057727],\n",
       "       [0.15891762],\n",
       "       [0.16132291],\n",
       "       [0.17488876],\n",
       "       [0.18371618],\n",
       "       [0.18929645],\n",
       "       [0.18412508],\n",
       "       [0.18705953],\n",
       "       [0.19761876],\n",
       "       [0.20182802],\n",
       "       [0.20317498],\n",
       "       [0.20661455],\n",
       "       [0.20574865],\n",
       "       [0.20283824],\n",
       "       [0.20115454],\n",
       "       [0.19482862],\n",
       "       [0.18939266],\n",
       "       [0.19425135],\n",
       "       [0.19196633],\n",
       "       [0.19155743],\n",
       "       [0.19915815],\n",
       "       [0.20353578],\n",
       "       [0.20355983],\n",
       "       [0.20144317],\n",
       "       [0.19898978],\n",
       "       [0.19035478],\n",
       "       [0.19605532],\n",
       "       [0.19413109],\n",
       "       [0.19112447],\n",
       "       [0.19073963],\n",
       "       [0.18922429],\n",
       "       [0.18996993],\n",
       "       [0.1900902 ],\n",
       "       [0.19802766],\n",
       "       [0.19569453],\n",
       "       [0.19706554],\n",
       "       [0.19694528],\n",
       "       [0.20115454],\n",
       "       [0.2070475 ],\n",
       "       [0.20252556],\n",
       "       [0.20206855],\n",
       "       [0.20365604],\n",
       "       [0.20365604],\n",
       "       [0.19297655],\n",
       "       [0.19304871],\n",
       "       [0.19420325],\n",
       "       [0.18975346],\n",
       "       [0.19704149],\n",
       "       [0.19696933],\n",
       "       [0.19889357],\n",
       "       [0.20363199],\n",
       "       [0.20206855],\n",
       "       [0.20202044],\n",
       "       [0.20192423],\n",
       "       [0.20430547],\n",
       "       [0.20865905],\n",
       "       [0.20649429],\n",
       "       [0.21349369],\n",
       "       [0.21387853],\n",
       "       [0.2119543 ],\n",
       "       [0.20844257],\n",
       "       [0.20853879],\n",
       "       [0.20175586],\n",
       "       [0.19427541],\n",
       "       [0.19523752],\n",
       "       [0.18669874],\n",
       "       [0.1843175 ],\n",
       "       [0.18542393],\n",
       "       [0.18626578],\n",
       "       [0.16875526],\n",
       "       [0.15911004],\n",
       "       [0.17484065],\n",
       "       [0.16644618],\n",
       "       [0.15588695],\n",
       "       [0.15891762],\n",
       "       [0.17407096],\n",
       "       [0.17799158],\n",
       "       [0.18527962],\n",
       "       [0.19879735],\n",
       "       [0.19745039],\n",
       "       [0.19605532],\n",
       "       [0.19417919],\n",
       "       [0.19761876],\n",
       "       [0.20483464],\n",
       "       [0.213181  ],\n",
       "       [0.21178593],\n",
       "       [0.2111365 ],\n",
       "       [0.20363199],\n",
       "       [0.20654239],\n",
       "       [0.20800962],\n",
       "       [0.20764883],\n",
       "       [0.20370415],\n",
       "       [0.20829826],\n",
       "       [0.21561034],\n",
       "       [0.21979555],\n",
       "       [0.21558629],\n",
       "       [0.21190619],\n",
       "       [0.2124113 ],\n",
       "       [0.21089597],\n",
       "       [0.20435358],\n",
       "       [0.20420926],\n",
       "       [0.19466025],\n",
       "       [0.18883945],\n",
       "       [0.17943476],\n",
       "       [0.19826819],\n",
       "       [0.18761275],\n",
       "       [0.18313891],\n",
       "       [0.18626578],\n",
       "       [0.18361996],\n",
       "       [0.18773301],\n",
       "       [0.19547805],\n",
       "       [0.19834035],\n",
       "       [0.18770896],\n",
       "       [0.1917258 ],\n",
       "       [0.19942273],\n",
       "       [0.19747444],\n",
       "       [0.20156344],\n",
       "       [0.20298256],\n",
       "       [0.20560433],\n",
       "       [0.21142514],\n",
       "       [0.21046302],\n",
       "       [0.19834035],\n",
       "       [0.18131088],\n",
       "       [0.18015634],\n",
       "       [0.17462417],\n",
       "       [0.17633193],\n",
       "       [0.17770295],\n",
       "       [0.17313289],\n",
       "       [0.18020445],\n",
       "       [0.18944077],\n",
       "       [0.2074083 ],\n",
       "       [0.20817799],\n",
       "       [0.22487072],\n",
       "       [0.22806975],\n",
       "       [0.23021046],\n",
       "       [0.2333614 ],\n",
       "       [0.23980758],\n",
       "       [0.2363199 ],\n",
       "       [0.23526158],\n",
       "       [0.23114853],\n",
       "       [0.23533373],\n",
       "       [0.23247144],\n",
       "       [0.23083584],\n",
       "       [0.23401082],\n",
       "       [0.23288034],\n",
       "       [0.23576669],\n",
       "       [0.23526158],\n",
       "       [0.23629585],\n",
       "       [0.23466025],\n",
       "       [0.23369814],\n",
       "       [0.2321828 ],\n",
       "       [0.24028863],\n",
       "       [0.24411305],\n",
       "       [0.24767288],\n",
       "       [0.24928443],\n",
       "       [0.24803367],\n",
       "       [0.24380036],\n",
       "       [0.24266987],\n",
       "       [0.24519543],\n",
       "       [0.24139507],\n",
       "       [0.2416356 ],\n",
       "       [0.23692123],\n",
       "       [0.2366807 ],\n",
       "       [0.22934456],\n",
       "       [0.23129284],\n",
       "       [0.22879134],\n",
       "       [0.22749248],\n",
       "       [0.22087793],\n",
       "       [0.22631389],\n",
       "       [0.22566446],\n",
       "       [0.22888755],\n",
       "       [0.22794949],\n",
       "       [0.23292844],\n",
       "       [0.22508719],\n",
       "       [0.22864702],\n",
       "       [0.23482862],\n",
       "       [0.24110643],\n",
       "       [0.24055322],\n",
       "       [0.23461215],\n",
       "       [0.24218882],\n",
       "       [0.2429104 ],\n",
       "       [0.24190018],\n",
       "       [0.24319904],\n",
       "       [0.24067348],\n",
       "       [0.24423331],\n",
       "       [0.24317498],\n",
       "       [0.24358388],\n",
       "       [0.24692724],\n",
       "       [0.25130487],\n",
       "       [0.24983764],\n",
       "       [0.24206855],\n",
       "       [0.23949489],\n",
       "       [0.2404089 ],\n",
       "       [0.26737222],\n",
       "       [0.28153939],\n",
       "       [0.28298256],\n",
       "       [0.28558028],\n",
       "       [0.2808659 ],\n",
       "       [0.28120265],\n",
       "       [0.28512327],\n",
       "       [0.28187613],\n",
       "       [0.28509922],\n",
       "       [0.28721587],\n",
       "       [0.28839447],\n",
       "       [0.29580277],\n",
       "       [0.30604931],\n",
       "       [0.30095009],\n",
       "       [0.29993987],\n",
       "       [0.29996392],\n",
       "       [0.30102225],\n",
       "       [0.30263379],\n",
       "       [0.30691521],\n",
       "       [0.31114853],\n",
       "       [0.31903788],\n",
       "       [0.32396873],\n",
       "       [0.33022249],\n",
       "       [0.33197835],\n",
       "       [0.32839447],\n",
       "       [0.31932652],\n",
       "       [0.31499699],\n",
       "       [0.30785328],\n",
       "       [0.32113049],\n",
       "       [0.31444378],\n",
       "       [0.32728803],\n",
       "       [0.32110643],\n",
       "       [0.3067709 ],\n",
       "       [0.3076368 ],\n",
       "       [0.30794949],\n",
       "       [0.31194227],\n",
       "       [0.30624173],\n",
       "       [0.31377029],\n",
       "       [0.3171377 ],\n",
       "       [0.31288034],\n",
       "       [0.32377631],\n",
       "       [0.32567649],\n",
       "       [0.32933253],\n",
       "       [0.33419122],\n",
       "       [0.34090198],\n",
       "       [0.33108839],\n",
       "       [0.32218882],\n",
       "       [0.32093806],\n",
       "       [0.32839447],\n",
       "       [0.30311485],\n",
       "       [0.29852075],\n",
       "       [0.31694528],\n",
       "       [0.30552014],\n",
       "       [0.31704149],\n",
       "       [0.31473241],\n",
       "       [0.30229705],\n",
       "       [0.31021046],\n",
       "       [0.31343355],\n",
       "       [0.31843656],\n",
       "       [0.30006013],\n",
       "       [0.31138906],\n",
       "       [0.30297054],\n",
       "       [0.29320505],\n",
       "       [0.29575466],\n",
       "       [0.30912808],\n",
       "       [0.31720986],\n",
       "       [0.28175586],\n",
       "       [0.2675887 ],\n",
       "       [0.27283223],\n",
       "       [0.28769693],\n",
       "       [0.28418521],\n",
       "       [0.27451594],\n",
       "       [0.24974143],\n",
       "       [0.24507517],\n",
       "       [0.23201443],\n",
       "       [0.24310283],\n",
       "       [0.24820204],\n",
       "       [0.22975346],\n",
       "       [0.20839447],\n",
       "       [0.20791341],\n",
       "       [0.19711365],\n",
       "       [0.20271798],\n",
       "       [0.20180397],\n",
       "       [0.21791942],\n",
       "       [0.21457607],\n",
       "       [0.21224293],\n",
       "       [0.22725195],\n",
       "       [0.20769693],\n",
       "       [0.20295851],\n",
       "       [0.18797354],\n",
       "       [0.19064342],\n",
       "       [0.18831028],\n",
       "       [0.18944077],\n",
       "       [0.19389056],\n",
       "       [0.18073361],\n",
       "       [0.17702946],\n",
       "       [0.18215274],\n",
       "       [0.16969333],\n",
       "       [0.15992784],\n",
       "       [0.14525556],\n",
       "       [0.13587492],\n",
       "       [0.16074564],\n",
       "       [0.15829224],\n",
       "       [0.15848467],\n",
       "       [0.16211666],\n",
       "       [0.16254961],\n",
       "       [0.12471437],\n",
       "       [0.13931449],\n",
       "       [0.13852075],\n",
       "       [0.14530367],\n",
       "       [0.15146121],\n",
       "       [0.15263981],\n",
       "       [0.14900782],\n",
       "       [0.1434997 ],\n",
       "       [0.15088394],\n",
       "       [0.15538184],\n",
       "       [0.15759471],\n",
       "       [0.15990379],\n",
       "       [0.15143716],\n",
       "       [0.15292844],\n",
       "       [0.14999399],\n",
       "       [0.16216476],\n",
       "       [0.15865304],\n",
       "       [0.15475646],\n",
       "       [0.1801804 ],\n",
       "       [0.18304269],\n",
       "       [0.18323512],\n",
       "       [0.19461215],\n",
       "       [0.20165965],\n",
       "       [0.20180397],\n",
       "       [0.19386651],\n",
       "       [0.1925917 ],\n",
       "       [0.19023452],\n",
       "       [0.19374624],\n",
       "       [0.19203848],\n",
       "       [0.19352977],\n",
       "       [0.19261575],\n",
       "       [0.19384245],\n",
       "       [0.19648827],\n",
       "       [0.19415514],\n",
       "       [0.19874925],\n",
       "       [0.20177992],\n",
       "       [0.20202044],\n",
       "       [0.2033193 ],\n",
       "       [0.1991822 ],\n",
       "       [0.20355983],\n",
       "       [0.20567649],\n",
       "       [0.20490679],\n",
       "       [0.20247745],\n",
       "       [0.19761876],\n",
       "       [0.19860493],\n",
       "       [0.21301263],\n",
       "       [0.21784726],\n",
       "       [0.2197715 ],\n",
       "       [0.22463019],\n",
       "       [0.23037883],\n",
       "       [0.23494889],\n",
       "       [0.231365  ],\n",
       "       [0.23528563],\n",
       "       [0.2519543 ],\n",
       "       [0.24223692],\n",
       "       [0.2366807 ],\n",
       "       [0.23199038],\n",
       "       [0.23603127],\n",
       "       [0.23663259],\n",
       "       [0.2395911 ],\n",
       "       [0.24269393],\n",
       "       [0.24938064]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(716, 100)\n",
      "(716,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 100)\n",
      "(339,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape), print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 50)           10400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 50)           20200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 50)           10400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 50)           20200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 48s 2s/step - loss: 0.0135 - val_loss: 0.0546\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 9s 737ms/step - loss: 0.0025 - val_loss: 0.0222\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 7s 606ms/step - loss: 7.3416e-04 - val_loss: 0.0204\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 8s 659ms/step - loss: 4.7682e-04 - val_loss: 0.0198\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 8s 711ms/step - loss: 3.7075e-04 - val_loss: 0.0197\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 8s 656ms/step - loss: 3.1407e-04 - val_loss: 0.0190\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 7s 628ms/step - loss: 3.1080e-04 - val_loss: 0.0185\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 9s 746ms/step - loss: 3.3730e-04 - val_loss: 0.0182\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 3.1614e-04 - val_loss: 0.0179\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 8s 697ms/step - loss: 2.8778e-04 - val_loss: 0.0174\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 2.8601e-04 - val_loss: 0.0175\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 9s 739ms/step - loss: 3.2569e-04 - val_loss: 0.0169\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 8s 715ms/step - loss: 2.7040e-04 - val_loss: 0.0166\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 9s 734ms/step - loss: 2.9034e-04 - val_loss: 0.0153\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 9s 785ms/step - loss: 3.2195e-04 - val_loss: 0.0153\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 7s 621ms/step - loss: 2.6525e-04 - val_loss: 0.0156\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 6s 535ms/step - loss: 2.4490e-04 - val_loss: 0.0144\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 6s 544ms/step - loss: 2.1259e-04 - val_loss: 0.0151\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 7s 577ms/step - loss: 2.1397e-04 - val_loss: 0.0161\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 6s 534ms/step - loss: 2.0445e-04 - val_loss: 0.0172\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 6s 527ms/step - loss: 2.2770e-04 - val_loss: 0.0160\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 6s 551ms/step - loss: 1.8924e-04 - val_loss: 0.0156\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 6s 545ms/step - loss: 1.9369e-04 - val_loss: 0.0147\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 6s 517ms/step - loss: 2.1316e-04 - val_loss: 0.0173\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 6s 520ms/step - loss: 1.9273e-04 - val_loss: 0.0153\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 6s 522ms/step - loss: 1.8883e-04 - val_loss: 0.0156\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 7s 623ms/step - loss: 2.2483e-04 - val_loss: 0.0166\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.9603e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-82657f88da1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1131\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformback to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Data RMSE\n",
    "math.sqrt(mean_squared_error(ytest,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting \n",
    "# shift train predictions for plotting\n",
    "look_back=100\n",
    "trainPredictPlot = numpy.empty_like(df1)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(df1)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df1))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=test_data[341:].reshape(1,-1)\n",
    "x_input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction for next 10 days\n",
    "from numpy import array\n",
    "\n",
    "lst_output=[]\n",
    "n_steps=100\n",
    "i=0\n",
    "while(i<30):\n",
    "    \n",
    "    if(len(temp_input)>100):\n",
    "        #print(temp_input)\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        print(len(temp_input))\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,101)\n",
    "day_pred=np.arange(101,131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(day_new,scaler.inverse_transform(df1[1158:]))\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1.tolist()\n",
    "df3.extend(lst_output)\n",
    "plt.plot(df3[1200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=scaler.inverse_transform(df3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
